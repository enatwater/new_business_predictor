{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Mandatory\n",
    "- decide how many years to allow\n",
    "- handle errors\n",
    "\n",
    "Optional\n",
    "- make a function to access the zipped & nonzipped files? Becuase need to read in as request, then pass to zipfile or pandas.\n",
    "- make a function to clean up column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and format imputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 5 user inputs will be\n",
    "\n",
    "year = 2015\n",
    "state_abbr = 'AL' \n",
    "table = 'B01001H'#'b00001'\n",
    "geo_unit = 'non_block' # data for block level only or all other geographies. Alternate: 'block'\n",
    "content_type = 'estimate' # retrieve estimates or margins of error. Alternate: 'margin' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run the `state_dict` cell below. \n",
    "\n",
    "# Tranform/format arguments\n",
    "\n",
    "year = str(year) # todo: confirm this is needed\n",
    "\n",
    "# standardize formatting\n",
    "state_abbr_upper = state_abbr.upper() # uppercase used in geographic call later\n",
    "state_abbr = state_abbr.lower()\n",
    "\n",
    "table = table.upper()\n",
    "\n",
    "# Get geographic level of data to use in data import url\n",
    "\n",
    "\n",
    "if geo_unit == 'block':\n",
    "    url_geo_unit = 'Tracts_Block_Groups_Only'\n",
    "elif geo_unit == 'non_block':\n",
    "    url_geo_unit = 'All_Geographies_Not_Tracts_Block_Groups'\n",
    "else:\n",
    "    print('Incorrect content type selected. Choose \"estimate\" or \"margin\".')\n",
    "\n",
    "\n",
    "# Get full state name. \n",
    "state_name = state_dict[state_abbr]\n",
    "\n",
    "# Get sequence table, the number that determines the table structure.\n",
    "sequence_table_url = 'http://www2.census.gov/programs-surveys/acs/summary_file/{0}/documentation/user_tools/ACS_5yr_Seq_Table_Number_Lookup.xls'.format(year)\n",
    "sequence_table_df = pd.read_excel(sequence_table_url, dtype=str)\n",
    "\n",
    "# clean up column names\n",
    "sequence_table_df.columns = sequence_table_df.columns.str.replace(' ', '_').str.lower()\n",
    "\n",
    "# Get sequence number, which determines which file should be used for table headers.\n",
    "sequence = sequence_table_df['sequence_number'].loc[sequence_table_df['table_id'] == table].max()\n",
    "\n",
    "# Left pad the sequence number for later use\n",
    "padded_sequence = '{:0>4}'.format(sequence_table_df['sequence_number'].loc[sequence_table_df['table_id'] == table].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of columns at the beginning of the dataframe that are common to all tables in the df.\n",
    "#last_common_column = int(sequence_table_df['start_position'].loc[sequence_table_df['table_id'] == table].min()) - 1\n",
    "\n",
    "# Harcoding for now b/c last common column always seems to be 6\n",
    "\n",
    "last_common_column = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data file\n",
    "\n",
    "url = 'https://www2.census.gov/programs-surveys/acs/summary_file/{0}/data/5_year_seq_by_state/{1}/{2}/{0}5{3}{4}000.zip'.\\\n",
    "format(year, state_name, url_geo_unit, state_abbr,padded_sequence)\n",
    "\n",
    "results = requests.get(url)\n",
    "# raise status?\n",
    "\n",
    "zipped = zipfile.ZipFile(io.BytesIO(results.content))\n",
    "\n",
    "for value in content_type:\n",
    "    if content_type == 'margin':\n",
    "        raw_csv = zipped.extract('m{0}5{1}{2}000.txt'.format(year,state_abbr, padded_sequence)) # saves in pwd, unless other is specified\n",
    "        raw_df = pd.read_csv(raw_csv, dtype=str,header=None)\n",
    "    elif content_type == 'estimate':\n",
    "        raw_csv = zipped.extract('e{0}5{1}{2}000.txt'.format(year, state_abbr, padded_sequence))\n",
    "        raw_df = pd.read_csv(raw_csv, dtype=str,header=None)\n",
    "    else:\n",
    "        print('no file') # need this?\n",
    "\n",
    "zipped.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working: \n",
    "https://www2.census.gov/programs-surveys/acs/summary_file/2015/data/5_year_seq_by_state/Alabama/All_Geographies_Not_Tracts_Block_Groups/20155al0001000.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header file\n",
    "# ** Laurel **\n",
    "# Should I not reuse the same variables?\n",
    "\n",
    "url = 'https://www2.census.gov/programs-surveys/acs/summary_file/{0}/data/{0}_5yr_Summary_FileTemplates.zip'.format(year)\n",
    "results = requests.get(url)\n",
    "\n",
    "zipped = zipfile.ZipFile(io.BytesIO(results.content))\n",
    "header_excel = zipped.extract('Seq{0}.xls'.format(sequence))\n",
    "\n",
    "# select estimate or margin of error tab\n",
    "if content_type == 'estimate':\n",
    "    header_tab = 'E'\n",
    "elif content_type == 'margin':\n",
    "    header_tab = 'M'\n",
    "else:\n",
    "    print('Incorrect content type selected. Choose \"estimate\" or \"margin\".')\n",
    "    \n",
    "header_df = pd.read_excel(header_excel, sheet_name= header_tab, dtype=str)\n",
    "\n",
    "zipped.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.5 s, sys: 762 ms, total: 43.3 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Import geographic location name file\n",
    "\n",
    "#https://www2.census.gov/programs-surveys/acs/summary_file/2015/documentation/geography/5_year_Mini_Geo.xlsx\n",
    "# Runtime issue - around 1 min\n",
    "# can keep entire or parsed file in my repo, if need be.\n",
    "geo_df = pd.read_excel('https://www2.census.gov/programs-surveys/acs/summary_file/{0}/documentation/geography/5_year_Mini_Geo.xlsx'.format(year),\n",
    "              sheet_name = state_abbr_upper, \n",
    "              dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append raw data and header files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change raw_df column names to align with header_df column names\n",
    "raw_df.columns = header_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = header_df.append(raw_df)\n",
    "\n",
    "# Reindex becasue line above results in 2 rows with index 0\n",
    "joined_df = joined_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select & clean the requested table's columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns that all tables in the df have in common\n",
    "common_df = joined_df.iloc[:, 0: last_common_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns for the table to be returned\n",
    "table_df = joined_df.loc[:, joined_df.columns.str.startswith('{0}_'.format(table))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data columns\n",
    "df = pd.concat([common_df, table_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace column names with first row.\n",
    "df.columns = df.iloc[0]\n",
    "df.drop([0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove table name and universe description from column names\n",
    "universe = (sequence_table_df['table_title'].loc[(sequence_table_df['table_id'] == table) & \\\n",
    "                                        (sequence_table_df['start_position'] == 'nan') & \\\n",
    "                                        (sequence_table_df['line_number'] == 'nan')]).to_string(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcode replacement of extra '%'\n",
    "df.columns = df.columns.str.replace(r'^.*{0}%'.format(universe),'', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge geographic location file.\n",
    "Merge on LOGRECNO\n",
    "Optional: drop state column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(geo_df, on='LOGRECNO', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the geographic data columns from the df\n",
    "geo_cols = [df.iloc[:,-1], df.iloc[:,-2]]\n",
    "df.drop(df.columns[[-1,-2,-3]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each element in the list of geo column series, insert it into postion 6, or last common column\n",
    "for i in geo_cols:\n",
    "    df.insert(last_common_column, i.name, i, allow_duplicates=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\\\n",
    "          .str.replace(' ','_')\\\n",
    "          .str.replace(':','')\\\n",
    "          .str.replace('%' , '')\\\n",
    "          .str.replace('(' , '_')\\\n",
    "          .str.replace (')' , '_')\\\n",
    "          .str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'name':'geographic_unit'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {\n",
    "'ak':'alaska',\n",
    "'al':'Alabama',\n",
    "'ar':'arkansas',\n",
    "'az':'arizona',\n",
    "'ca':'california',\n",
    "'co':'colorado',\n",
    "'ct':'connecticut',\n",
    "'dc':'districtofcolumbia',\n",
    "'de':'delaware',\n",
    "'fl':'florida',\n",
    "'ga':'georgia',\n",
    "'gu':'guam',\n",
    "'hi':'hawaii',\n",
    "'ia':'iowa',\n",
    "'id':'idaho',\n",
    "'il':'illinois',\n",
    "'in':'indiana',\n",
    "'ks':'kansas',\n",
    "'ky':'kentucky',\n",
    "'la':'louisiana',\n",
    "'ma':'massachusetts',\n",
    "'md':'maryland',\n",
    "'me':'maine',\n",
    "'mi':'michigan',\n",
    "'mn':'minnesota',\n",
    "'mo':'missouri',\n",
    "'ms':'mississippi',\n",
    "'mt':'montana',\n",
    "'na':'national',\n",
    "'nc':'northcarolina',\n",
    "'nd':'northdakota',\n",
    "'ne':'nebraska',\n",
    "'nh':'newhampshire',\n",
    "'nj':'newjersey',\n",
    "'nm':'newmexico',\n",
    "'nv':'nevada',\n",
    "'ny':'newyork',\n",
    "'oh':'ohio',\n",
    "'ok':'oklahoma',\n",
    "'or':'oregon',\n",
    "'pa':'pennsylvania',\n",
    "'pr':'puertorico',\n",
    "'ri':'rhodeisland',\n",
    "'sc':'southcarolina',\n",
    "'sd':'southdakota',\n",
    "'tn':'tennessee',\n",
    "'tx':'texas',\n",
    "'ut':'utah',\n",
    "'va':'virginia',\n",
    "'vi':'virginislands',\n",
    "'vt':'vermont',\n",
    "'wa':'washington',\n",
    "'wi':'wisconsin',\n",
    "'wv':'westvirginia',\n",
    "'wy':'wyoming' \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
