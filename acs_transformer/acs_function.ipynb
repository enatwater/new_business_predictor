{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo\n",
    "- delete raw_csv and header_excel from directory.\n",
    "- figure out how to handle the state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acs_transformer(year, state_abbr, table, geo_unit, content_type):\n",
    "    '''\n",
    "    return a dataframe of American Community Survey 5 year data for a given state, table, and year.\n",
    "    :param year: The end year of the 5 year period, in 4 digits. E.g. 2015.\n",
    "    :param state_abbr: The two-letter state abbreviation. Washington, DC is 'dc' and Puerto Rico is 'pr'\n",
    "    :param table: The table id, e.g. 'B01001'\n",
    "    :param geo_unit: Select 'block' to return data for all census blocks in the state. Select 'non-block' to return data for \n",
    "    all other geographic units in the state.\n",
    "    :param content_type: Select 'estimate' for counts only and 'margin' for margins of error only.\n",
    "    :return: dataframe and description of selected table  \n",
    "    '''\n",
    "    \n",
    "    # Import modules\n",
    "    \n",
    "    import io\n",
    "    import os\n",
    "    import re\n",
    "    import zipfile\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    \n",
    "    # First run the `state_dict` cell below. \n",
    "\n",
    "    ##############################################\n",
    "    #          Transform arguments and           #\n",
    "    #         create additional variables        #\n",
    "    ##############################################\n",
    "    \n",
    "    year = str(year) # todo: confirm this is needed\n",
    "    \n",
    "    # standardize formatting\n",
    "    state_abbr_upper = state_abbr.upper() # uppercase used in geographic call later\n",
    "    state_abbr = state_abbr.lower()\n",
    "    \n",
    "    table = table.upper()\n",
    "    \n",
    "    # Get geographic level of data to use in data import url\n",
    "    \n",
    "    if geo_unit == 'block':\n",
    "        url_geo_unit = 'Tracts_Block_Groups_Only'\n",
    "    elif geo_unit == 'non_block':\n",
    "        url_geo_unit = 'All_Geographies_Not_Tracts_Block_Groups'\n",
    "    else:\n",
    "        print('Incorrect geographic unit selected. Choose \"block\" or \"non_block\".')\n",
    "    \n",
    "    \n",
    "    # Get full state name. \n",
    "    state_name = state_dict[state_abbr]\n",
    "    \n",
    "    # Get sequence table, the number that determines the table structure.\n",
    "    sequence_table_url = 'http://www2.census.gov/programs-surveys/acs/summary_file/{0}/documentation/user_tools/ACS_5yr_Seq_Table_Number_Lookup.xls'.format(year)\n",
    "    sequence_table_df = pd.read_excel(sequence_table_url, dtype=str)\n",
    "    \n",
    "    # clean up column names\n",
    "    sequence_table_df.columns = sequence_table_df.columns.str.replace(' ', '_').str.lower()\n",
    "    \n",
    "    # Get sequence number, which determines which file should be used for table headers.\n",
    "    sequence = sequence_table_df['sequence_number'].loc[sequence_table_df['table_id'] == table].max()\n",
    "    \n",
    "    # Left pad the sequence number for later use\n",
    "    padded_sequence = '{:0>4}'.format(sequence_table_df['sequence_number'].loc[sequence_table_df['table_id'] == table].max())\n",
    "    \n",
    "    # Get the number of columns at the beginning of the dataframe that are common to all tables in the df.\n",
    "    #last_common_column = int(sequence_table_df['start_position'].loc[sequence_table_df['table_id'] == table].min()) - 1\n",
    "    \n",
    "    # Harcoding for now b/c last common column always seems to be 6\n",
    "    \n",
    "    last_common_column = 6\n",
    "    \n",
    "\n",
    "    ##############################################\n",
    "    #                 Import files               #\n",
    "    ##############################################     \n",
    "    \n",
    "    # raw data file\n",
    "\n",
    "    url = 'https://www2.census.gov/programs-surveys/acs/summary_file/{0}/data/5_year_seq_by_state/{1}/{2}/{0}5{3}{4}000.zip'.\\\n",
    "    format(year, state_name, url_geo_unit, state_abbr,padded_sequence)\n",
    "    \n",
    "    results = requests.get(url)\n",
    "    \n",
    "    zipped = zipfile.ZipFile(io.BytesIO(results.content))\n",
    "    \n",
    "    for value in content_type:\n",
    "        if content_type == 'margin':\n",
    "            raw_csv = zipped.extract('m{0}5{1}{2}000.txt'.format(year,state_abbr, padded_sequence)) # saves in pwd, unless other is specified\n",
    "            raw_df = pd.read_csv(raw_csv, dtype=str,header=None)\n",
    "        elif content_type == 'estimate':\n",
    "            raw_csv = zipped.extract('e{0}5{1}{2}000.txt'.format(year, state_abbr, padded_sequence))\n",
    "            raw_df = pd.read_csv(raw_csv, dtype=str,header=None)\n",
    "        else:\n",
    "            print('no file') # need this?\n",
    "    \n",
    "    zipped.close()\n",
    "    \n",
    "    \n",
    "    # Header file\n",
    "    \n",
    "    url = 'https://www2.census.gov/programs-surveys/acs/summary_file/{0}/data/{0}_5yr_Summary_FileTemplates.zip'.format(year)\n",
    "    results = requests.get(url)\n",
    "    \n",
    "    zipped = zipfile.ZipFile(io.BytesIO(results.content))\n",
    "    header_excel = zipped.extract('Seq{0}.xls'.format(sequence))\n",
    "    \n",
    "    # select estimate or margin of error tab\n",
    "    if content_type == 'estimate':\n",
    "        header_tab = 'E'\n",
    "    elif content_type == 'margin':\n",
    "        header_tab = 'M'\n",
    "    else:\n",
    "        print('Incorrect content type selected. Choose \"estimate\" or \"margin\".')\n",
    "        \n",
    "    header_df = pd.read_excel(header_excel, sheet_name= header_tab, dtype=str)\n",
    "    \n",
    "    zipped.close()\n",
    "    \n",
    "\n",
    "    # Geographic location name file\n",
    "    \n",
    "    geo_df = pd.read_excel('https://www2.census.gov/programs-surveys/acs/summary_file/{0}/documentation/geography/5_year_Mini_Geo.xlsx'.format(year),\n",
    "                  sheet_name = state_abbr_upper, \n",
    "                  dtype=str)\n",
    "\n",
    "\n",
    "    ##############################################\n",
    "    #          Join raw and header dfs           #\n",
    "    ############################################## \n",
    "    \n",
    "    # Change raw_df column names to align with header_df column names\n",
    "    raw_df.columns = header_df.columns\n",
    "    \n",
    "    joined_df = header_df.append(raw_df)\n",
    "    \n",
    "    # Reindex becasue line above results in 2 rows with index 0\n",
    "    joined_df = joined_df.reset_index(drop=True)\n",
    "        \n",
    "    \n",
    "    ##############################################\n",
    "    #              Select & clean                #\n",
    "    #        the requested table's columns       #\n",
    "    ##############################################    \n",
    "    \n",
    "    # Select the columns that all tables in the df have in common\n",
    "    common_df = joined_df.iloc[:, 0: last_common_column]\n",
    "    \n",
    "    # select the columns for the table to be returned\n",
    "    table_df = joined_df.loc[:, joined_df.columns.str.startswith('{0}_'.format(table))]\n",
    "    \n",
    "    # final data columns\n",
    "    df = pd.concat([common_df, table_df],axis=1)\n",
    "    \n",
    "    # replace column names with first row.\n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop([0], inplace = True)\n",
    "    \n",
    "    # remove table name and universe description from column names\n",
    "    universe = (sequence_table_df['table_title'].loc[(sequence_table_df['table_id'] == table) & \\\n",
    "                                            (sequence_table_df['start_position'] == 'nan') & \\\n",
    "                                            (sequence_table_df['line_number'] == 'nan')]).to_string(index=False)\n",
    "    \n",
    "    \n",
    "    # hardcode replacement of extra '%'\n",
    "    df.columns = df.columns.str.replace(r'^.*{0}'.format(universe),'', regex=True)\n",
    "        \n",
    " \n",
    "    ##############################################\n",
    "    #             Join geographic df             #\n",
    "    ##############################################\n",
    "    \n",
    "    df = df.merge(geo_df, on='LOGRECNO', how='left')\n",
    "    \n",
    "    # extract the geographic data columns from the df\n",
    "    geo_cols = [df.iloc[:,-1], df.iloc[:,-2]]\n",
    "    df.drop(df.columns[[-1,-2,-3]], axis=1, inplace=True)\n",
    "    \n",
    "    # for each element in the list of geo column series, insert it into postion 6, or last common column\n",
    "    for i in geo_cols:\n",
    "        df.insert(last_common_column, i.name, i, allow_duplicates=False)\n",
    "    \n",
    "    ##############################################\n",
    "    #                Clean columns               #\n",
    "    ##############################################\n",
    "    \n",
    "    df.columns = df.columns.str.strip()\\\n",
    "          .str.replace(' ','_')\\\n",
    "          .str.replace(':','')\\\n",
    "          .str.replace('%' , '')\\\n",
    "          .str.replace('(' , '_')\\\n",
    "          .str.replace (')' , '_')\\\n",
    "          .str.lower()\n",
    "    \n",
    "    df.rename(columns={'name':'geographic_unit'}, inplace=True)\n",
    "    \n",
    "    ##############################################\n",
    "    #      Delete objects and return df          #\n",
    "    ##############################################\n",
    "    \n",
    "    del(sequence_table_df, raw_csv, raw_df, header_excel, header_df, geo_df, common_df, table_df, geo_cols)\n",
    "    \n",
    "    print('Dataframe for table {0} for the state of {1}'.format(table,state_name.capitalize()))\n",
    "    return df\n",
    "    os.remove(header_excel) # This did not remove the file from the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 11 µs\n",
      "Dataframe for table B00001 for the state of Alabama\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# function test\n",
    "df = acs_transformer(2015, 'al', 'B00001', 'non_block','estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {\n",
    "'ak':'alaska',\n",
    "'al':'Alabama',\n",
    "'ar':'arkansas',\n",
    "'az':'arizona',\n",
    "'ca':'california',\n",
    "'co':'colorado',\n",
    "'ct':'connecticut',\n",
    "'dc':'districtofcolumbia',\n",
    "'de':'delaware',\n",
    "'fl':'florida',\n",
    "'ga':'georgia',\n",
    "'gu':'guam',\n",
    "'hi':'hawaii',\n",
    "'ia':'iowa',\n",
    "'id':'idaho',\n",
    "'il':'illinois',\n",
    "'in':'indiana',\n",
    "'ks':'kansas',\n",
    "'ky':'kentucky',\n",
    "'la':'louisiana',\n",
    "'ma':'massachusetts',\n",
    "'md':'maryland',\n",
    "'me':'maine',\n",
    "'mi':'michigan',\n",
    "'mn':'minnesota',\n",
    "'mo':'missouri',\n",
    "'ms':'mississippi',\n",
    "'mt':'montana',\n",
    "'na':'national',\n",
    "'nc':'northcarolina',\n",
    "'nd':'northdakota',\n",
    "'ne':'nebraska',\n",
    "'nh':'newhampshire',\n",
    "'nj':'newjersey',\n",
    "'nm':'newmexico',\n",
    "'nv':'nevada',\n",
    "'ny':'newyork',\n",
    "'oh':'ohio',\n",
    "'ok':'oklahoma',\n",
    "'or':'oregon',\n",
    "'pa':'pennsylvania',\n",
    "'pr':'puertorico',\n",
    "'ri':'rhodeisland',\n",
    "'sc':'southcarolina',\n",
    "'sd':'southdakota',\n",
    "'tn':'tennessee',\n",
    "'tx':'texas',\n",
    "'ut':'utah',\n",
    "'va':'virginia',\n",
    "'vi':'virginislands',\n",
    "'vt':'vermont',\n",
    "'wa':'washington',\n",
    "'wi':'wisconsin',\n",
    "'wv':'westvirginia',\n",
    "'wy':'wyoming' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
